#!/usr/bin/env python3
"""
MQTT å›¾åƒæ•°æ®è¯»å–å’Œä¿å­˜å·¥å…·
æ”¯æŒä»MQTTæ¥æ”¶Base64ç¼–ç çš„å›¾åƒæ•°æ®å¹¶ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶
"""

import paho.mqtt.client as mqtt
import json
import base64
import cv2
import numpy as np
import argparse
import os
import sys
from datetime import datetime
import time
import zipfile
import shutil
import threading
from concurrent.futures import ThreadPoolExecutor
import queue


class MQTTImageReceiver:
    """MQTTå›¾åƒæ¥æ”¶å™¨"""
    
    def __init__(self, broker_host='localhost', broker_port=1883, save_dir='mqtt_images', 
                 archive_enabled=False, archive_batch_size=10, archive_dir='mqtt_archives'):
        self.broker_host = broker_host
        self.broker_port = broker_port
        self.save_dir = save_dir
        self.client = None
        self.image_count = 0
        
        # å‹ç¼©æ‰“åŒ…ç›¸å…³å‚æ•°
        self.archive_enabled = archive_enabled
        self.archive_batch_size = archive_batch_size
        self.archive_dir = archive_dir
        self.archive_count = 0
        self.pending_files = []  # å¾…æ‰“åŒ…çš„æ–‡ä»¶åˆ—è¡¨
        
        # å¼‚æ­¥å‹ç¼©ç›¸å…³
        self.archive_lock = threading.Lock()  # ä¿æŠ¤ pending_files åˆ—è¡¨
        self.archive_executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="archive")
        self.archive_futures = []  # è·Ÿè¸ªå‹ç¼©ä»»åŠ¡
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(self.save_dir, exist_ok=True)
        print(f"å›¾åƒä¿å­˜ç›®å½•: {os.path.abspath(self.save_dir)}")
        
        # å¦‚æœå¯ç”¨å‹ç¼©æ‰“åŒ…ï¼Œåˆ›å»ºå½’æ¡£ç›®å½•
        if self.archive_enabled:
            os.makedirs(self.archive_dir, exist_ok=True)
            print(f"å‹ç¼©åŒ…ä¿å­˜ç›®å½•: {os.path.abspath(self.archive_dir)}")
            print(f"å‹ç¼©æ‰¹æ¬¡å¤§å°: {self.archive_batch_size} å¼ å›¾ç‰‡/åŒ…")
        
    def setup_mqtt(self):
        """è®¾ç½®MQTTå®¢æˆ·ç«¯"""
        try:
            self.client = mqtt.Client(
                client_id='image_receiver',
                callback_api_version=mqtt.CallbackAPIVersion.VERSION1
            )
            self.client.on_connect = self.on_connect
            self.client.on_message = self.on_message
            self.client.on_disconnect = self.on_disconnect
            
            print(f"æ­£åœ¨è¿æ¥åˆ° MQTT æœåŠ¡å™¨ {self.broker_host}:{self.broker_port}...")
            self.client.connect(self.broker_host, self.broker_port, 60)
            return True
            
        except Exception as e:
            print(f"MQTTè¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def on_connect(self, client, userdata, flags, rc):
        """MQTTè¿æ¥å›è°ƒ"""
        if rc == 0:
            print("âœ“ å·²è¿æ¥åˆ°MQTTæœåŠ¡å™¨")
            # è®¢é˜…æ‰€æœ‰å¯èƒ½çš„å›¾åƒè¯é¢˜
            topics = [
                'ros2/image_compressed/data',
                'ros2/image_raw/data', 
                'ros2/camera/image',
                #'ros2/+/+',  # é€šé…ç¬¦ï¼Œæ¥æ”¶æ‰€æœ‰ROS2ç›¸å…³è¯é¢˜
            ]
            
            for topic in topics:
                client.subscribe(topic)
                print(f"å·²è®¢é˜…è¯é¢˜: {topic}")
        else:
            print(f"âœ— MQTTè¿æ¥å¤±è´¥ï¼Œé”™è¯¯ç : {rc}")
    
    def on_disconnect(self, client, userdata, rc):
        """MQTTæ–­å¼€å›è°ƒ"""
        print("MQTTè¿æ¥å·²æ–­å¼€")
    
    def add_file_to_archive_queue(self, filepath):
        """æ·»åŠ æ–‡ä»¶åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        if not self.archive_enabled:
            return
        
        with self.archive_lock:
            self.pending_files.append(filepath)
            pending_count = len(self.pending_files)
            
        print(f"  æ·»åŠ åˆ°æ‰“åŒ…é˜Ÿåˆ—: {os.path.basename(filepath)} (é˜Ÿåˆ—ä¸­ {pending_count}/{self.archive_batch_size})")
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹æ¬¡å¤§å°ï¼ˆä¸é˜»å¡ï¼‰
        if pending_count >= self.archive_batch_size:
            self.schedule_archive_creation()
    
    def schedule_archive_creation(self):
        """å®‰æ’å¼‚æ­¥åˆ›å»ºå‹ç¼©åŒ…"""
        with self.archive_lock:
            if len(self.pending_files) >= self.archive_batch_size:
                # åˆ›å»ºå½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶åˆ—è¡¨å‰¯æœ¬
                files_to_archive = self.pending_files[:self.archive_batch_size]
                # ä»å¾…æ‰“åŒ…åˆ—è¡¨ä¸­ç§»é™¤è¿™äº›æ–‡ä»¶
                self.pending_files = self.pending_files[self.archive_batch_size:]
                
                # æäº¤å¼‚æ­¥å‹ç¼©ä»»åŠ¡
                future = self.archive_executor.submit(self._create_archive_async, files_to_archive)
                self.archive_futures.append(future)
                
                print(f"  ğŸ”„ å·²å®‰æ’å‹ç¼©ä»»åŠ¡ï¼Œå‰©ä½™é˜Ÿåˆ—: {len(self.pending_files)} ä¸ªæ–‡ä»¶")
    
    def _create_archive_async(self, files_to_archive):
        """å¼‚æ­¥åˆ›å»ºå‹ç¼©åŒ…ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰"""
        try:
            self.archive_count += 1
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            archive_name = f"mqtt_images_batch_{self.archive_count:04d}_{timestamp}.zip"
            archive_path = os.path.join(self.archive_dir, archive_name)
            
            print(f"\nğŸ“¦ åå°åˆ›å»ºå‹ç¼©åŒ…: {archive_name}")
            print(f"   åŒ…å« {len(files_to_archive)} ä¸ªæ–‡ä»¶")
            
            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
                for file_path in files_to_archive:
                    if os.path.exists(file_path):
                        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºå½’æ¡£å†…çš„æ–‡ä»¶å
                        arcname = os.path.basename(file_path)
                        zipf.write(file_path, arcname)
                        print(f"   âœ“ å·²æ·»åŠ : {arcname}")
                    else:
                        print(f"   âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # è·å–å‹ç¼©åŒ…å¤§å°ä¿¡æ¯
            archive_size = os.path.getsize(archive_path)
            original_size = sum(os.path.getsize(f) for f in files_to_archive if os.path.exists(f))
            compression_ratio = (1 - archive_size / original_size) * 100 if original_size > 0 else 0
            
            print(f"   ğŸ“Š å‹ç¼©å®Œæˆ:")
            print(f"      åŸå§‹å¤§å°: {original_size:,} å­—èŠ‚")
            print(f"      å‹ç¼©å: {archive_size:,} å­—èŠ‚")
            print(f"      å‹ç¼©ç‡: {compression_ratio:.1f}%")
            print(f"   ğŸ’¾ ä¿å­˜åˆ°: {archive_path}")
            
            # å¯é€‰ï¼šåˆ é™¤åŸå§‹æ–‡ä»¶
            self._cleanup_files_async(files_to_archive)
            
            return archive_path
            
        except Exception as e:
            print(f"âœ— åå°åˆ›å»ºå‹ç¼©åŒ…å¤±è´¥: {str(e)}")
            return None
    
    def _cleanup_files_async(self, files_to_cleanup):
        """å¼‚æ­¥æ¸…ç†æ–‡ä»¶"""
        print(f"   ğŸ—‘ï¸  æ¸…ç†åŸå§‹æ–‡ä»¶:")
        for file_path in files_to_cleanup:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    print(f"      âœ“ å·²åˆ é™¤: {os.path.basename(file_path)}")
            except Exception as e:
                print(f"      âœ— åˆ é™¤å¤±è´¥: {os.path.basename(file_path)} - {str(e)}")
    
    def create_archive(self):
        """ç«‹å³åˆ›å»ºå‹ç¼©åŒ…ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œä¿ç•™ç”¨äºæ‰‹åŠ¨è°ƒç”¨ï¼‰"""
        if not self.pending_files:
            return
            
        with self.archive_lock:
            files_to_archive = self.pending_files.copy()
            self.pending_files.clear()
        
        return self._create_archive_async(files_to_archive)
    
    def cleanup_archive_tasks(self):
        """æ¸…ç†å·²å®Œæˆçš„å¼‚æ­¥å‹ç¼©ä»»åŠ¡"""
        if not self.archive_futures:
            return
            
        completed_futures = []
        for future in self.archive_futures:
            if future.done():
                completed_futures.append(future)
                try:
                    result = future.result()  # è·å–ç»“æœï¼Œå¦‚æœæœ‰å¼‚å¸¸ä¼šæŠ›å‡º
                    if result:
                        print(f"  âœ… å‹ç¼©ä»»åŠ¡å®Œæˆ: {os.path.basename(result)}")
                except Exception as e:
                    print(f"  âŒ å‹ç¼©ä»»åŠ¡å¤±è´¥: {e}")
        
        # ä»åˆ—è¡¨ä¸­ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
        for future in completed_futures:
            self.archive_futures.remove(future)
    
    def finalize_remaining_files(self):
        """å¤„ç†å‰©ä½™æœªæ‰“åŒ…çš„æ–‡ä»¶"""
        if self.archive_enabled and self.pending_files:
            print(f"\nğŸ“¦ å¤„ç†å‰©ä½™çš„ {len(self.pending_files)} ä¸ªæ–‡ä»¶...")
            self.create_archive()
        
        # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥å‹ç¼©ä»»åŠ¡å®Œæˆ
        if hasattr(self, 'archive_executor') and self.archive_executor:
            print("â³ ç­‰å¾…å‹ç¼©ä»»åŠ¡å®Œæˆ...")
            self.archive_executor.shutdown(wait=True)
            print("âœ… æ‰€æœ‰å‹ç¼©ä»»åŠ¡å·²å®Œæˆ")
    
    def decode_and_save_image(self, image_data, topic, timestamp=None):
        """è§£ç å¹¶ä¿å­˜å›¾åƒæ•°æ®"""
        try:
            if timestamp is None:
                timestamp = datetime.now()
            
            print(f"  å¼€å§‹è§£ç å›¾åƒæ•°æ®ï¼Œç±»å‹: {type(image_data)}")
            
            # è§£ç Base64æ•°æ®
            if isinstance(image_data, dict):
                # ç»“æ„åŒ–æ•°æ®
                encoding = image_data.get('encoding', 'unknown')
                data_type = image_data.get('data_type', 'unknown')
                base64_data = image_data.get('data', '')
                
                print(f"  è§£ç å‚æ•° - ç¼–ç : {encoding}, ç±»å‹: {data_type}, Base64é•¿åº¦: {len(base64_data)}")
                print(f"  åŸå§‹å¤§å°: {image_data.get('original_size', 'unknown')} å­—èŠ‚")
                
                if encoding == 'base64' and base64_data:
                    print(f"  å¼€å§‹Base64è§£ç ...")
                    try:
                        # è§£ç Base64æ•°æ®
                        img_bytes = base64.b64decode(base64_data)
                        print(f"  Base64è§£ç æˆåŠŸï¼Œå¾—åˆ° {len(img_bytes)} å­—èŠ‚")
                        
                        # ç”Ÿæˆæ–‡ä»¶å
                        safe_topic = topic.replace('/', '_').replace('+', 'all')
                        timestamp_str = timestamp.strftime('%Y%m%d_%H%M%S_%f')[:-3]  # æ¯«ç§’ç²¾åº¦
                        filename = f"{safe_topic}_{timestamp_str}_{self.image_count:04d}.jpg"
                        filepath = os.path.join(self.save_dir, filename)
                        
                        print(f"  å‡†å¤‡ä¿å­˜åˆ°: {filepath}")
                        
                        if data_type == 'uint8_array':
                            # å¯¹äºå‹ç¼©å›¾åƒæ•°æ®ï¼Œç›´æ¥ä¿å­˜
                            print(f"  ä¿å­˜ä¸ºå‹ç¼©å›¾åƒæ–‡ä»¶...")
                            with open(filepath, 'wb') as f:
                                f.write(img_bytes)
                            print(f"âœ“ å‹ç¼©å›¾åƒå·²ä¿å­˜: {filename} ({len(img_bytes)} å­—èŠ‚)")
                            
                            # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                            self.add_file_to_archive_queue(filepath)
                            
                        elif data_type in ['bytes', 'numpy_array']:
                            # å°è¯•ä½¿ç”¨OpenCVè§£ç 
                            print(f"  å°è¯•OpenCVè§£ç ...")
                            nparr = np.frombuffer(img_bytes, np.uint8)
                            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                            
                            if img is not None:
                                cv2.imwrite(filepath, img)
                                print(f"âœ“ å›¾åƒå·²ä¿å­˜: {filename} (å°ºå¯¸: {img.shape})")
                                # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                                self.add_file_to_archive_queue(filepath)
                            else:
                                # å¦‚æœOpenCVè§£ç å¤±è´¥ï¼Œç›´æ¥ä¿å­˜äºŒè¿›åˆ¶æ•°æ®
                                print(f"  OpenCVè§£ç å¤±è´¥ï¼Œä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶...")
                                bin_filepath = filepath.replace('.jpg', '.bin')
                                with open(bin_filepath, 'wb') as f:
                                    f.write(img_bytes)
                                print(f"âœ“ äºŒè¿›åˆ¶æ•°æ®å·²ä¿å­˜: {filename.replace('.jpg', '.bin')} ({len(img_bytes)} å­—èŠ‚)")
                                # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                                self.add_file_to_archive_queue(bin_filepath)
                        else:
                            # æœªçŸ¥ç±»å‹ï¼Œå°è¯•ç›´æ¥ä¿å­˜
                            print(f"  æœªçŸ¥æ•°æ®ç±»å‹ï¼Œå°è¯•ç›´æ¥ä¿å­˜...")
                            with open(filepath, 'wb') as f:
                                f.write(img_bytes)
                            print(f"âœ“ æ•°æ®å·²ä¿å­˜: {filename} ({len(img_bytes)} å­—èŠ‚)")
                            # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                            self.add_file_to_archive_queue(filepath)
                        
                        self.image_count += 1
                        return True
                        
                    except Exception as decode_error:
                        print(f"  âœ— Base64è§£ç å¤±è´¥: {str(decode_error)}")
                        return False
                else:
                    print(f"  âœ— ä¸æ˜¯æœ‰æ•ˆçš„Base64ç¼–ç æ•°æ® (encoding={encoding}, data_len={len(base64_data)})")
                    return False
                    
            elif isinstance(image_data, str):
                # ç›´æ¥çš„Base64å­—ç¬¦ä¸²
                try:
                    img_bytes = base64.b64decode(image_data)
                    
                    # ç”Ÿæˆæ–‡ä»¶å
                    safe_topic = topic.replace('/', '_').replace('+', 'all')
                    timestamp_str = timestamp.strftime('%Y%m%d_%H%M%S_%f')[:-3]
                    filename = f"{safe_topic}_{timestamp_str}_{self.image_count:04d}.jpg"
                    filepath = os.path.join(self.save_dir, filename)
                    
                    # å°è¯•OpenCVè§£ç 
                    nparr = np.frombuffer(img_bytes, np.uint8)
                    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    
                    if img is not None:
                        cv2.imwrite(filepath, img)
                        print(f"âœ“ å›¾åƒå·²ä¿å­˜: {filename} (å°ºå¯¸: {img.shape})")
                        # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                        self.add_file_to_archive_queue(filepath)
                    else:
                        # ç›´æ¥ä¿å­˜äºŒè¿›åˆ¶æ•°æ®
                        bin_filepath = filepath.replace('.jpg', '.bin')
                        with open(bin_filepath, 'wb') as f:
                            f.write(img_bytes)
                        print(f"âœ“ äºŒè¿›åˆ¶æ•°æ®å·²ä¿å­˜: {filename.replace('.jpg', '.bin')}")
                        # æ·»åŠ åˆ°å‹ç¼©æ‰“åŒ…é˜Ÿåˆ—
                        self.add_file_to_archive_queue(bin_filepath)
                    
                    self.image_count += 1
                    return True
                    
                except Exception as e:
                    print(f"è§£ç ç›´æ¥Base64æ•°æ®å¤±è´¥: {str(e)}")
                    
            return False
            
        except Exception as e:
            print(f"è§£ç å’Œä¿å­˜å›¾åƒå¤±è´¥: {str(e)}")
            return False
    
    def on_message(self, client, userdata, msg):
        """MQTTæ¶ˆæ¯å›è°ƒ"""
        try:
            # å®šæœŸæ¸…ç†å·²å®Œæˆçš„å¼‚æ­¥å‹ç¼©ä»»åŠ¡
            self.cleanup_archive_tasks()
            
            topic = msg.topic
            timestamp = datetime.now()
            
            print(f"\n[{timestamp.strftime('%H:%M:%S')}] æ”¶åˆ°æ¶ˆæ¯:")
            print(f"  è¯é¢˜: {topic}")
            print(f"  æ•°æ®é•¿åº¦: {len(msg.payload)} å­—èŠ‚")
            
            # å°è¯•è§£ææ¶ˆæ¯
            try:
                # é¦–å…ˆå°è¯•è§£æä¸ºJSON
                message_text = msg.payload.decode('utf-8')
                message_data = json.loads(message_text)
                
                print(f"  æ¶ˆæ¯ç±»å‹: JSON")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒæ•°æ®
                if isinstance(message_data, dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„å›¾åƒæ•°æ®å­—æ®µ
                    if 'data' in message_data:
                        data_field = message_data['data']
                        
                        if isinstance(data_field, dict):
                            # æ£€æŸ¥ä¸åŒçš„ç¼–ç æ ¼å¼
                            print(f"  æ•°æ®å­—æ®µæ˜¯å­—å…¸ï¼Œé”®: {list(data_field.keys())}")
                            
                            if data_field.get('encoding') == 'base64':
                                # æ–°æ ¼å¼ï¼šåŒ…å«encodingå­—æ®µ
                                print(f"  å‘ç°Base64ç¼–ç å›¾åƒæ•°æ® (æ–°æ ¼å¼)")
                                success = self.decode_and_save_image(data_field, topic, timestamp)
                                if success:
                                    print(f"  âœ“ å›¾åƒå¤„ç†æˆåŠŸ")
                                else:
                                    print(f"  âœ— å›¾åƒå¤„ç†å¤±è´¥")
                            elif data_field.get('type') == 'uint8_array' and 'data' in data_field:
                                # MQTTæ¥å£çš„è‡ªå®šä¹‰åºåˆ—åŒ–æ ¼å¼
                                print(f"  å‘ç°uint8_arrayå›¾åƒæ•°æ® (MQTTæ ¼å¼)")
                                print(f"  æ•°æ®å¤§å°: {data_field.get('size', 0)} å­—èŠ‚")
                                print(f"  Base64æ•°æ®é•¿åº¦: {len(data_field.get('data', ''))} å­—ç¬¦")
                                
                                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                                unified_data = {
                                    'encoding': 'base64',
                                    'data_type': 'uint8_array',
                                    'original_size': data_field.get('size', 0),
                                    'data': data_field.get('data', ''),
                                    'timestamp': datetime.now().isoformat()
                                }
                                print(f"  è½¬æ¢åçš„æ•°æ®æ ¼å¼: {list(unified_data.keys())}")
                                success = self.decode_and_save_image(unified_data, topic, timestamp)
                                if success:
                                    print(f"  âœ“ å›¾åƒå¤„ç†æˆåŠŸ")
                                else:
                                    print(f"  âœ— å›¾åƒå¤„ç†å¤±è´¥")
                            else:
                                print(f"  æœªè¯†åˆ«çš„æ•°æ®å­—æ®µæ ¼å¼")
                                print(f"  æ•°æ®å­—æ®µç»“æ„: {list(data_field.keys())}")
                                print(f"  æ•°æ®å­—æ®µé¢„è§ˆ: {str(data_field)[:200]}...")
                        elif isinstance(data_field, str) and len(data_field) > 100:
                            # å¯èƒ½æ˜¯ç›´æ¥çš„Base64å­—ç¬¦ä¸²
                            print(f"  å‘ç°å¯èƒ½çš„Base64å­—ç¬¦ä¸² (é•¿åº¦: {len(data_field)})")
                            success = self.decode_and_save_image(data_field, topic, timestamp)
                            if success:
                                print(f"  âœ“ å›¾åƒå¤„ç†æˆåŠŸ")
                            else:
                                print(f"  âœ— å›¾åƒå¤„ç†å¤±è´¥")
                        else:
                            print(f"  æ•°æ®å­—æ®µç±»å‹: {type(data_field)}, å†…å®¹é¢„è§ˆ: {str(data_field)[:100]}...")
                    else:
                        print(f"  æ¶ˆæ¯ç»“æ„: {list(message_data.keys())}")
                        # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹é¢„è§ˆ
                        preview = json.dumps(message_data, indent=2, ensure_ascii=False)[:300]
                        print(f"  å†…å®¹é¢„è§ˆ: {preview}...")
                else:
                    print(f"  æ¶ˆæ¯ä¸æ˜¯å­—å…¸æ ¼å¼: {type(message_data)}")
                    
            except UnicodeDecodeError:
                print(f"  æ¶ˆæ¯ç±»å‹: äºŒè¿›åˆ¶æ•°æ®")
                print(f"  å‰32å­—èŠ‚: {msg.payload[:32].hex()}")
                
            except json.JSONDecodeError:
                print(f"  æ¶ˆæ¯ç±»å‹: éJSONæ–‡æœ¬")
                try:
                    text_content = msg.payload.decode('utf-8')
                    print(f"  æ–‡æœ¬å†…å®¹é¢„è§ˆ: {text_content[:100]}...")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥çš„Base64æ•°æ®
                    if len(text_content) > 100 and text_content.replace('\n', '').replace(' ', '').isalnum():
                        print(f"  å°è¯•ä½œä¸ºBase64æ•°æ®å¤„ç†...")
                        success = self.decode_and_save_image(text_content, topic, timestamp)
                        if success:
                            print(f"  âœ“ å›¾åƒå¤„ç†æˆåŠŸ")
                        else:
                            print(f"  âœ— å›¾åƒå¤„ç†å¤±è´¥")
                except:
                    print(f"  æ— æ³•è§£ç ä¸ºæ–‡æœ¬")
            
            print("-" * 60)
            
        except Exception as e:
            print(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
    
    def start_receiving(self):
        """å¼€å§‹æ¥æ”¶å›¾åƒ"""
        if not self.setup_mqtt():
            return False
        
        print("\nå›¾åƒæ¥æ”¶å™¨å·²å¯åŠ¨")
        print("ç­‰å¾…å›¾åƒæ•°æ®...")
        print("æŒ‰ Ctrl+C é€€å‡º")
        print("=" * 60)
        
        try:
            self.client.loop_forever()
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
            if self.client:
                self.client.loop_stop()
                self.client.disconnect()
        
        # å¤„ç†å‰©ä½™æœªæ‰“åŒ…çš„æ–‡ä»¶
        self.finalize_remaining_files()
        
        print(f"\næ¥æ”¶ä¼šè¯ç»“æŸï¼Œå…±ä¿å­˜ {self.image_count} å¼ å›¾åƒ")
        if self.archive_enabled:
            print(f"å…±åˆ›å»º {self.archive_count} ä¸ªå‹ç¼©åŒ…")
            print(f"å‹ç¼©åŒ…ä¿å­˜åœ¨: {os.path.abspath(self.archive_dir)}")
        return True


def main():
    parser = argparse.ArgumentParser(description='MQTTå›¾åƒæ¥æ”¶å’Œä¿å­˜å·¥å…·')
    parser.add_argument('--host', default='localhost', help='MQTTæœåŠ¡å™¨åœ°å€')
    parser.add_argument('--port', type=int, default=1883, help='MQTTæœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--save-dir', default='mqtt_images', help='å›¾åƒä¿å­˜ç›®å½•')
    parser.add_argument('--list-topics', action='store_true', help='ä»…åˆ—å‡ºæ´»è·ƒçš„MQTTè¯é¢˜')
    
    # å‹ç¼©æ‰“åŒ…ç›¸å…³å‚æ•°
    parser.add_argument('--enable-archive', action='store_true', 
                       help='å¯ç”¨è‡ªåŠ¨å‹ç¼©æ‰“åŒ…åŠŸèƒ½')
    parser.add_argument('--archive-batch-size', type=int, default=100,
                       help='æ¯ä¸ªå‹ç¼©åŒ…åŒ…å«çš„å›¾ç‰‡æ•°é‡ (é»˜è®¤: 100)')
    parser.add_argument('--archive-dir', default='mqtt_archives',
                       help='å‹ç¼©åŒ…ä¿å­˜ç›®å½• (é»˜è®¤: mqtt_archives)')
    
    args = parser.parse_args()
    
    if args.list_topics:
        # ç®€å•çš„è¯é¢˜åˆ—è¡¨åŠŸèƒ½
        print("ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ´»è·ƒçš„MQTTè¯é¢˜:")
        print(f"mosquitto_sub -h {args.host} -p {args.port} -t '+' -v")
        return
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("="*60)
    print("MQTTå›¾åƒæ¥æ”¶å™¨é…ç½®:")
    print(f"  MQTTæœåŠ¡å™¨: {args.host}:{args.port}")
    print(f"  å›¾åƒä¿å­˜ç›®å½•: {args.save_dir}")
    if args.enable_archive:
        print(f"  å‹ç¼©æ‰“åŒ…: å¯ç”¨")
        print(f"  æ‰¹æ¬¡å¤§å°: {args.archive_batch_size} å¼ å›¾ç‰‡/åŒ…")
        print(f"  å‹ç¼©åŒ…ç›®å½•: {args.archive_dir}")
    else:
        print(f"  å‹ç¼©æ‰“åŒ…: ç¦ç”¨ (ä½¿ç”¨ --enable-archive å¯ç”¨)")
    print("="*60)
    
    # åˆ›å»ºå¹¶å¯åŠ¨å›¾åƒæ¥æ”¶å™¨
    receiver = MQTTImageReceiver(
        broker_host=args.host, 
        broker_port=args.port, 
        save_dir=args.save_dir,
        archive_enabled=args.enable_archive,
        archive_batch_size=args.archive_batch_size,
        archive_dir=args.archive_dir
    )
    receiver.start_receiving()


if __name__ == '__main__':
    main()
